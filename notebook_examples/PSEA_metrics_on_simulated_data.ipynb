{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dowell-Lab/psea/blob/main/notebook_examples/PSEA_metrics_on_simulated_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YPUBJg5Xl_g3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pull in the raw data"
      ],
      "metadata": {
        "id": "ouR4ihxs8mFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url=\"https://raw.githubusercontent.com/Dowell-Lab/psea/refs/heads/main/testdata/sim_psea_scores_20241015-122448.adjpval.csv\"\n",
        "resultsdf = pd.read_csv(url, index_col=0)\n"
      ],
      "metadata": {
        "id": "mx_HR3rIpblH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#which_pvalue_column = \"p_value_BenjaminiHochberg\"\n",
        "#which_pvalue_column = \"p_value_bonf\"\n",
        "#which_pvalue_column = \"p_value_BenjaminiYekutieli\"\n",
        "which_pvalue_column = \"p_value_holm\"\n"
      ],
      "metadata": {
        "id": "wDodLpsXP0Cz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label the simulated comorbidites as as TRUE or FALSE"
      ],
      "metadata": {
        "id": "maO4b3mCpxUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## functions"
      ],
      "metadata": {
        "id": "rkyheYV0TIIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this code splits the column name to tell us which gene it was simulated from and what parmaters were used\n",
        "def parse_simulated_binary_att(row):\n",
        "  simulated_binary_attribute = row[\"binary_attribute\"]\n",
        "  # Split the simulated_binary_attribute string by underscores\n",
        "  parts = simulated_binary_attribute.split('_')\n",
        "  # Extract the gene name\n",
        "  genename = \"_\".join(parts[0:4])\n",
        "  # Extract the other values using a dictionary for easier parsing\n",
        "  extracted_values = {}\n",
        "  for part in parts[1:]:\n",
        "      if 'Truesamplesize' in part:\n",
        "          extracted_values['samples_true'] = int(part.replace('Truesamplesize', ''))\n",
        "      elif 'biassamplesize' in part:\n",
        "          extracted_values['samples_true_bias'] = int(part.replace('biassamplesize', ''))\n",
        "      elif 'Zscorevaluebais' in part:\n",
        "          extracted_values['Zscore_valuebais'] = float(part.replace('Zscorevaluebais', ''))\n",
        "      elif 'sigma' in part:\n",
        "          extracted_values['Zscore_valuebais_sigma'] = float(part.replace('sigma', ''))\n",
        "      elif 'top' in part:\n",
        "          extracted_values['top_or_bottom'] = \"top\"\n",
        "      elif 'bottom' in part:\n",
        "          extracted_values['top_or_bottom'] = \"bottom\"\n",
        "      elif 'pba' in part:\n",
        "          extracted_values['percent_binary_attributes_thatarevaluebias'] = float(part.replace('pba', ''))\n",
        "\n",
        "  return genename, extracted_values\n",
        "\n",
        "\n",
        "def mark_actul_TRUE_FALSE_links(df, min_people_with_bias_transcription=0):\n",
        "  \"\"\" min_people_with_bias_transcription is a number. More than min_people_with_bias_transcription must have the bias for it to count as a TRUE gene-comorbid linkage\"\"\"\n",
        "  #split the comorbid name into all its parts\n",
        "  df[[\"genename\", \"other_dict\"]] = df.apply(lambda row: parse_simulated_binary_att(row), axis=1, result_type=\"expand\")\n",
        "  #put its parts (now new columns) back on the orginal data frame\n",
        "  final_df = pd.concat([resultsdf.drop(['other_dict'], axis=1), resultsdf['other_dict'].apply(pd.Series)], axis=1)\n",
        "  final_df['Actual_Label'] = 'FALSE'  # Initialize all values to 'FP'\n",
        "  # Create a boolean mask for rows where 'value' matches 'genename' and 'samples_true_bias' is not 0\n",
        "  mask = (final_df['value'] == final_df['genename']) & (final_df['samples_true_bias'] > min_people_with_bias_transcription)\n",
        "  # Set 'Actual_Label' to 'TRUE' for rows matching the mask\n",
        "  final_df.loc[mask, 'Actual_Label'] = 'TRUE'\n",
        "  return final_df"
      ],
      "metadata": {
        "id": "l6lknJ5VpyMg"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# functions for creating ROC curve and confusion matrix"
      ],
      "metadata": {
        "id": "KH-FupVo9Jal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " def confusion_matrix(df, cutoff=0.05):\n",
        "  confusiondf = df[[which_pvalue_column, \"Actual_Label\"]].copy()\n",
        "  confusiondf[\"Predicted_Label\"] = np.where(confusiondf[which_pvalue_column] <= cutoff, \"TRUE\", \"FALSE\")\n",
        "  cm = confusiondf.groupby([\"Actual_Label\", \"Predicted_Label\"]).size().reset_index(name=\"count\")\n",
        "  cm['Confusion_Category'] = 'Unknown'\n",
        "  cm.loc[(cm.Actual_Label == 'FALSE') & (cm.Predicted_Label == 'TRUE'), 'Confusion_Category'] = 'False Positive'\n",
        "  cm.loc[(cm.Actual_Label == 'TRUE') & (cm.Predicted_Label == 'TRUE'), 'Confusion_Category'] = 'True Positive'\n",
        "  cm.loc[(cm.Actual_Label == 'TRUE') & (cm.Predicted_Label == 'FALSE'), 'Confusion_Category'] = 'False Negative'\n",
        "  cm.loc[(cm.Actual_Label == 'FALSE') & (cm.Predicted_Label == 'FALSE'), 'Confusion_Category'] = 'True Negative'\n",
        "  try:\n",
        "    TP = cm.loc[cm.Confusion_Category == 'True Positive', 'count'].values[0]\n",
        "  except:\n",
        "    TP = 0\n",
        "  try:\n",
        "    FN = cm.loc[cm.Confusion_Category == 'False Negative', 'count'].values[0]\n",
        "  except:\n",
        "    FN = 0\n",
        "  try:\n",
        "    FP = cm.loc[cm.Confusion_Category == 'False Positive', 'count'].values[0]\n",
        "  except:\n",
        "    FP = 0\n",
        "  try:\n",
        "    TN = cm.loc[cm.Confusion_Category == 'True Negative', 'count'].values[0]\n",
        "  except:\n",
        "    TN = 0\n",
        "  FPrate = FP/(FP+TN)\n",
        "  TPrate = TP/(TP+FN)\n",
        "  return cm, TPrate, FPrate\n",
        "\n",
        "def create_ROC_curve(df):\n",
        "  TPrates = []\n",
        "  FPrates = []\n",
        "  cutoffs = [cutoff for cutoff in np.arange(0, 1.01, 0.01)]\n",
        "  for cutoff in cutoffs:\n",
        "    cm, TPrate, FPrate = confusion_matrix(df, cutoff=cutoff)\n",
        "    TPrates.append(TPrate)\n",
        "    FPrates.append(FPrate)\n",
        "  ROCdf = pd.DataFrame({\"TPrate\": TPrates, \"FPrate\": FPrates, \"cutoff\": cutoffs})\n",
        "  print(ROCdf)\n",
        "  return ROCdf\n",
        "\n",
        "def plot_ROC_curve(ROCdf, graphtitle=\"ROCcurve\"):\n",
        "  fig = px.line(ROCdf, x=\"FPrate\", y=\"TPrate\", title=graphtitle)\n",
        "  fig.update_layout(xaxis_range=[0, 1], yaxis_range=[0, 1])\n",
        "  fig.update_xaxes(title_text=\"False Positive Rate\")\n",
        "  fig.update_yaxes(title_text=\"True Positive Rate\")\n",
        "  fig.show()\n",
        "\n",
        "\n",
        "def plot_ROCdf_single_set_parmaters(df, min_people_with_bias_transcription=0):\n",
        "  final_df = mark_actul_TRUE_FALSE_links(df, min_people_with_bias_transcription=min_people_with_bias_transcription)\n",
        "  ROCdf = create_ROC_curve(final_df)\n",
        "  plot_ROC_curve(ROCdf)"
      ],
      "metadata": {
        "id": "cBG0KSKe0tIi"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = mark_actul_TRUE_FALSE_links(resultsdf)"
      ],
      "metadata": {
        "id": "JurMkD5VWSEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df"
      ],
      "metadata": {
        "id": "pw_0PaT9WVw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_ROCdf_single_set_parmaters(resultsdf, min_people_with_bias_transcription=0)"
      ],
      "metadata": {
        "id": "YVsjP_rq7Jp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_simulation_parameters_neccesary(df, min_people_with_bias_transcription=0):\n",
        "  final_df = mark_actul_TRUE_FALSE_links(df, min_people_with_bias_transcription=min_people_with_bias_transcription)\n",
        "  #samples_true \tsamples_true_bias \tZscore_valuebais \tZscore_valuebais_sigma \ttop_or_bottom \tpercent_binary_attributes_thatarevaluebias\n",
        "  for n_comorbid in final_df[\"samples_true\"].unique():\n",
        "    for n_comorbid_bias in final_df[\"samples_true_bias\"].unique():\n",
        "      for Zscore_valuebais in final_df[\"Zscore_valuebais\"].unique():\n",
        "        final_df_subset = final_df[(final_df[\"samples_true\"] == n_comorbid) & (final_df[\"samples_true_bias\"] == n_comorbid_bias) & (final_df[\"Zscore_valuebais\"] == Zscore_valuebais)]\n",
        "        if final_df_subset.shape[0] != 0:\n",
        "          title = f\"n_comorbid: {n_comorbid}, n_comorbid_bias: {n_comorbid_bias}, Zscore_valuebais: {Zscore_valuebais}\"\n",
        "          print(title)\n",
        "          ROCdf = create_ROC_curve(final_df_subset)\n",
        "          plot_ROC_curve(ROCdf, graphtitle=title)"
      ],
      "metadata": {
        "id": "m-ouGgMUWOMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_simulation_parameters_neccesary(resultsdf)"
      ],
      "metadata": {
        "id": "9x-vks8ho_9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df[\"log_\"+which_pvalue_column]=np.log(final_df[which_pvalue_column])\n",
        "\n"
      ],
      "metadata": {
        "id": "y2lj3acj4rpz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}